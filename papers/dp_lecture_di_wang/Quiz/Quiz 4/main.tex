\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\newcommand{\numpy}{{\tt numpy}}    % tt font for numpy
\usepackage{amsmath,amsfonts,amssymb,graphicx,mathtools,flexisym}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\topmargin -.5in
\textheight 9in
\oddsidemargin -.25in
\evensidemargin -.25in
\textwidth 7in

\begin{document}

% ========== Edit your name here
\author{Name and KAUST ID}
\title{Quiz 4}
\maketitle

\medskip

% ========== Begin answering questions here
\begin{enumerate}

\item Consider the following statements. Judge whether each of them is true or false. You donâ€™t need to explain the reason.
\begin{itemize}

\item Consider the output perturbation Algorithm 1 in Lecture 13. We must assume that the loss function $\ell$ is strongly convex. 
\item In the Algorithm 2 of output perturbation in Lecture 13. The number of iterations $T$ does not need  be chosen carefully to achieve the small the error bound. 
\item In the objective perturbation method Algorithm 1 in Lecture 14. In practice we can use any optimization method to solve the perturbed objective function and get some approximate solution. However,  rigorously speaking this may be not $(\epsilon, \delta)$ or $\epsilon$-DP.  
\item In the DP-SGD (Algorithm 3) in Lecture 15. The number of iterations $T$  need  be chosen carefully to achieve the small the error bound. 

\end{itemize}

\end{enumerate}
 
% ========== Continue adding items as needed



\end{document}
\grid
\grid